 # Where to get input
    input {
      # syslog inputs
      tcp {
        port => 5000
        type => "syslog"
      }
      udp {
        port => 5000
        type => "syslog"
      }
     
      # CoreOS journal input
      tcp {
        codec => "line"
        port => 5301
        tags => ["coreos","docker"]
        type => "systemd"
      }
     
      # Logspout input
      udp {
        codec => "plain"
        port => 5006
        tags => ["docker"]
        type => "logspout"
      }
    }
     
    # Some Filtering
    filter {
      # syslog/systemd filter
      if [type] == "syslog" or [type] == "systemd" {
        grok {
          match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{SYSLOGPROG}: %{GREEDYDATA:syslog_message}" }
          add_field => [ "received_at", "%{@timestamp}" ]
        }
        syslog_pri { }
        date { match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ] }
     
        if !("_grokparsefailure" in [tags]) {
          mutate {
            replace => { "message" => "%{syslog_message}" }
            remove_field => [  "syslog_message", "syslog_program" ]
          }
        }
         
       if "nginx" in [message]{mutate { add_tag => ["NGINX-ACCESS"] }  }       

        # Remove spurious fields that have names changed or been aggregated
        mutate { remove_field => [ "syslog_hostname", "syslog_timestamp" ] }
      }
     
      # Docker filter
      if [program] == "dockerd" {
        kv {
          source => "message"
          remove_field => [ "time" ]
          prefix => "docker_"
        }
        mutate { rename => { "docker_level" => "docker_loglevel" } }
    #    mutate {
    #      replace => { "message" => "time=\"%{TIMESTAMP_ISO8601:docker_ts}\" level=%{LOGLEVEL:docker_loglevel} msg=\"%{GREEDYDATA:docker_msg}\"" }
    #    }
        if !("_grokparsefailure" in [tags]) {
          mutate {
            replace => { "message" => "%{docker_msg}" }
            remove_field => [ "%{docker_msg}" ]
          }
        }
      }
     
      # Logspout filter
      if [type] == "logspout" {
        grok {
          match => { 
#"message" => "%{SYSLOG5424PRI}%{NONNEGINT:ver} +(?:%{TIMESTAMP_ISO8601:ts}|-) +(?:%{HOSTNAME:containerid}|-) +(?:%{NOTSPACE:containername}|-) +(?:%{NOTSPACE:proc}|-) +(?:%{WORD:msgid}|-) +(?:%{SYSLOG5424SD:sd}|-|) +%{GREEDYDATA:msg}" 
"message" => "<%{NUMBER}>%{TIMESTAMP_ISO8601:time}%{SPACE}%{WORD:container_hash}%{SPACE}%{HOSTNAME:container_name}"
 }
        }
        syslog_pri { }
        date { match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ] }

         # Remove spurious fields that have names changed or been aggregated
        mutate { 
              remove_field => [ "syslog_hostname", "syslog_message", "syslog_timestamp" ]
#              add_field => { "docker name" => "%{container_name}" }
        }
      }       
        
     
      # Add GeoIP
      geoip { source => "%{IPORHOST}" }
    }
     
    # Where to send output
    output {
      # Send output to standard output device/interface
      stdout {
        codec => rubydebug
      }

  # Parse failed messages to separate index
  if "_grokparsefailure" in [tags] or "_jsonparsefailure" in [tags] {
    elasticsearch {
      host => ["localhost:9200"]
    #  host => "$COREOS_PRIVATE_IPV4"
      index => "parse-err-%{+YYYY.MM.dd}"
      protocol  => "http"
    }
  }

# Elasticsearch output
  elasticsearch {
    host => ["localhost:9200"]
  #  host => "$COREOS_PRIVATE_IPV4"
    index => "logstash-%{+YYYY.MM.dd}"
    protocol  => "http"
  }
}

