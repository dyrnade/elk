# Where to get input
input {

    # syslog inputs
        tcp {
        port => 5000
        type => "syslog"
    }
    udp {
        port => 5000
        type => "syslog"
    }

    # CoreOS journal input
    tcp {
        codec => "line"
        port => 5301
        tags => ["coreos","docker"]
        type => "systemd"
    }

    udp {
       port => 5007
       tags => ["docker"]
       type => "multiline_logspout"
    }

    # Logspout input
    udp {
        port => 5006
        tags => ["docker"]
        type => "logspout"
    }
}

# Some Filtering
filter {

    # syslog/systemd filter
    if [type] == "syslog" or [type] == "systemd" {
        grok {
            match => { "message" => "%{SYSLOGTIMESTAMP:syslog_timestamp} %{SYSLOGHOST:syslog_hostname} %{SYSLOGPROG}: %{GREEDYDATA:syslog_message}" }
            add_field => [ "received_at", "%{@timestamp}" ]
        }

        syslog_pri { }
        date { match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" , "ISO8601"] }

        if !("_grokparsefailure" in [tags]) {
            mutate {
                replace => { "message" => "%{syslog_message}" }
                remove_field => [  "syslog_message", "syslog_program" ]
            }
        }

        # Remove spurious fields that have names changed or been aggregated
        mutate { remove_field => [ "syslog_hostname", "syslog_timestamp" ] }
    }

    if [program] == "haproxy" {

        grok {
            match => { "message" => "%{IP:client}:%{INT:port} \[%{MONTHDAY}/%{MONTH}/%{YEAR}:(?!<[0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![0-9]).%{INT}\] %{NOTSPACE:frontend_name} %{NOTSPACE:backend_name}/%{NOTSPACE:server_name} %{INT:time_request}/%{INT:time_queue}/%{INT:time_backend_connect}/%{INT:time_backend_response}/%{NOTSPACE:time_duration} %{INT:http_status_code} %{NOTSPACE:bytes_read} %{DATA:captured_request_cookie} %{DATA:captured_response_cookie} %{NOTSPACE:termination_state} %{INT:actconn}/%{INT:feconn}/%{INT:beconn}/%{INT:srvconn}/%{NOTSPACE:retries} %{INT:srv_queue}/%{INT:backend_queue} ( )?{%{HOST:host}}%{SPACE}\"%{GREEDYDATA:msg}\"" }
        }

        mutate {
            replace => { "message" => "%{msg}" }
            remove_field => [ "msg", "termination_state", "time_backend_connect", "time_backend_response", "time_duration", "time_queue", "time_request", "backend_queue", "beconn", "bytes_read", "captured_request_cookie", "captured_response_cookie", "feconn", "srv_queue", "srvconn", "actconn", "retries" ]
        }

        date { match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ]
                          "timezone" => "Europe/Istanbul"}
    }


    # Docker filter
    if [program] == "dockerd" {
        kv {
            source => "message"
            remove_field => [ "time" ]
            prefix => "docker_"
        }

        mutate { rename => { "docker_level" => "docker_loglevel" } }

        if !("_grokparsefailure" in [tags]) {
            mutate {
                replace => { "message" => "%{docker_msg}" }
                remove_field => [ "%{docker_msg}" ]
            }
        }
    }

   if [type] == "multiline_logspout" {

        multiline {  pattern => "^\s" negate => true  what =>  "previous"  }
        grok { match => ["message", "<%{NUMBER}>%{TIMESTAMP_ISO8601:time}%{SPACE}%{WORD:container_hash}%{SPACE}%{HOSTNAME:container_name}%{GREEDYDATA:msg}"] }
        syslog_pri { }
        date { match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ] }

        # Remove spurious fields that have names changed or been aggregated
        mutate {
            replace => ["message" , "%{msg}"]
            remove_field => [ "msg" ]
        }
   }


    # Logspout filter
    if [type] == "logspout" {
        grok {
            match => {
                #"message" => "%{SYSLOG5424PRI}%{NONNEGINT:ver} +(?:%{TIMESTAMP_ISO8601:ts}|-) +(?:%{HOSTNAME:containerid}|-) +(?:%{NOTSPACE:containername}|-) +(?:%{NOTSPACE:proc}|-) +(?:%{WORD:msgid}|-) +(?:%{SYSLOG5424SD:sd}|-|) +%{GREEDYDATA:msg}"
                #"message" => "<%{NUMBER}>%{TIMESTAMP_ISO8601:time}%{SPACE}%{WORD:container_hash}%{SPACE}%{HOSTNAME:container_name}%{SPACE}[%{NUMBER}]%{SPACE}+(?:%{NOTSPACE:proc}|-) +(?:%{WORD:msgid}|-) +(?:%{SYSLOG5424SD:sd}|-|)%{SPACE}+%{MONTH:sd}%{SPACE}+%{HOUR}:%{MINUTE}:%{ISO8601_SECOND}+(?:%{NOTSPACE:procz}|-)%{SPACE}+(?:%{NOTSPACE:proczs}|-)%{SPACE}+%{GREEDYDATA:msg}"
                #"message" => "[%{NUMBER}]%{SPACE}+(?:%{NOTSPACE:proc}|-) +(?:%{WORD:msgid}|-) +(?:%{SYSLOG5424SD:sd}|-|)%{SPACE}+%{MONTH:sd}%{SPACE}+%{HOUR}:%{MINUTE}:%{ISO8601_SECOND}+(?:%{NOTSPACE:procz}|-)%{SPACE}+(?:%{NOTSPACE:proczs}|-)%{SPACE}+%{GREEDYDATA:msg}"

                "message" => "<%{NUMBER}>%{TIMESTAMP_ISO8601:time}%{SPACE}%{WORD:container_hash}%{SPACE}%{HOSTNAME:container_name}%{GREEDYDATA:msg}"
            }
        }

    syslog_pri { }
    date { match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss", "ISO8601" ] }

    # Remove spurious fields that have names changed or been aggregated
        mutate {
            replace => ["message" , "%{msg}"]
            remove_field => [ "msg" ]
        }
    }


    # Add GeoIP
    geoip { source => "%{IPORHOST}" }
}

# Where to send output
output {

    # Parse failed messages to separate index
    if "_grokparsefailure" in [tags] or "_jsonparsefailure" in [tags] {
        elasticsearch {
            host => ["localhost:9200"]
            #  host => "$COREOS_PRIVATE_IPV4"
            index => "parse-err-%{+YYYY.MM.dd}"
            protocol  => "http"
        }
    }

    # Elasticsearch output
    elasticsearch {
        host => ["localhost:9200"]
        #  host => "$COREOS_PRIVATE_IPV4"
        index => "logstash-%{+YYYY.MM.dd}"
        protocol  => "http"
    }

}

